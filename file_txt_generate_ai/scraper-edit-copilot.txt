# scraper.py - Scraper sử dụng Selenium và Regex để lấy danh sách sản phẩm
import sys
import io
import json
import logging
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import WebDriverException
from webdriver_manager.chrome import ChromeDriverManager
from scraper_beauti import extract_images_and_titles

# --- CẤU HÌNH ---
REQUEST_TIMEOUT = 30
WAIT_TIME = 10

# --- XỬ LÝ ENCODING CHO WINDOWS ---
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

def get_driver():
    """Khởi tạo Chrome WebDriver."""
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64)')
    chrome_options.add_experimental_option("excludeSwitches", ["enable-logging"])
    
    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.set_page_load_timeout(REQUEST_TIMEOUT)
        return driver
    except WebDriverException as e:
        print(json.dumps({"error": f"Driver Error: {str(e)}"}))
        sys.exit(1)

def scrape_images(url):
    """Chỉ lấy hình ảnh + tiêu đề từ trang sản phẩm."""
    driver = None
    results = []
    try:
        driver = get_driver()
        driver.get(url)
        WebDriverWait(driver, WAIT_TIME).until(EC.presence_of_element_located((By.TAG_NAME, "body")))
        
        page_source = driver.page_source
        image_map = extract_images_and_titles(page_source, url)

        for title, img_url in image_map.items():
            results.append({
                "title": title,
                "image": img_url,
                "link": url
            })
        return results
    except Exception as e:
        return [{"url": url, "error": str(e)}]
    finally:
        if driver:
            driver.quit()

# --- MAIN EXECUTION BLOCK ---
if __name__ == "__main__":
    # Nhận nhiều URL từ tham số dòng lệnh
    urls = sys.argv[1:]
    if not urls:
        print(json.dumps({"error": "No URLs provided"}, ensure_ascii=False))
    else:
        all_results = []
        for url in urls:
            data = scrape_images(url)
            all_results.extend(data)
        print(json.dumps(all_results, ensure_ascii=False))
